# ğŸ¤– Configuration Claude - Guide Rapide

## âœ… Migration vers Claude ComplÃ©tÃ©e!

Le systÃ¨me a Ã©tÃ© modifiÃ© pour utiliser **Claude (Anthropic)** au lieu d'OpenAI.

---

## ğŸ”‘ Votre ClÃ© API

Votre clÃ© Claude est dÃ©jÃ  configurÃ©e dans `.env`:

```bash
ANTHROPIC_API_KEY=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
```

âš ï¸ **IMPORTANT**: Ne partagez JAMAIS cette clÃ© publiquement!

---

## ğŸ“¦ Installation

### 1. Installer les dÃ©pendances

```bash
cd rag_system
pip install -r requirements.txt
```

Cela installera:
- âœ… `langchain-anthropic` (pour Claude)
- âœ… `anthropic` (SDK Claude)
- âœ… `sentence-transformers` (embeddings locaux)
- âœ… `chromadb` (base vectorielle)

### 2. VÃ©rifier la configuration

```bash
python config.py
```

Vous devriez voir:
```
âœ… Configuration validated successfully!

Using:
  - Vector Store: chromadb
  - Embeddings: Local (all-MiniLM-L6-v2)
  - LLM: Claude (claude-3-5-sonnet-20241022)
  - Database Dir: ...
```

---

## ğŸš€ DÃ©marrage

### Option 1: Script Automatique

```bash
python quick_start.py
```

### Option 2: Manuel

```bash
# 1. Construire la base vectorielle
python build_vectorstore.py --rebuild

# 2. Lancer le systÃ¨me
python rag_query.py
```

---

## ğŸ¯ ModÃ¨les Claude Disponibles

Vous pouvez changer le modÃ¨le dans `.env`:

### Claude 3.5 Sonnet (RecommandÃ©) â­
```bash
LLM_MODEL=claude-3-5-sonnet-20241022
```
- âœ… Meilleur Ã©quilibre qualitÃ©/vitesse/coÃ»t
- âœ… Excellent pour raisonnement complexe
- âœ… 200K tokens de contexte
- ğŸ’° $3/M input tokens, $15/M output tokens

### Claude 3 Opus (QualitÃ© Maximale)
```bash
LLM_MODEL=claude-3-opus-20240229
```
- âœ… Meilleure qualitÃ© absolue
- âœ… Raisonnement le plus avancÃ©
- âŒ Plus lent et plus cher
- ğŸ’° $15/M input tokens, $75/M output tokens

### Claude 3 Haiku (Rapide & Ã‰conomique)
```bash
LLM_MODEL=claude-3-haiku-20240307
```
- âœ… TrÃ¨s rapide
- âœ… TrÃ¨s Ã©conomique
- âŒ QualitÃ© lÃ©gÃ¨rement infÃ©rieure
- ğŸ’° $0.25/M input tokens, $1.25/M output tokens

---

## ğŸ”§ DiffÃ©rences avec OpenAI

### âœ… Avantages de Claude

1. **Contexte plus large**: 200K tokens vs 128K pour GPT-4
2. **Meilleure comprÃ©hension**: Excellent pour documents longs
3. **Moins de hallucinations**: Plus factuel
4. **Meilleur franÃ§ais**: QualitÃ© native excellente
5. **Prix compÃ©titifs**: Sonnet moins cher que GPT-4

### âš ï¸ DiffÃ©rences Importantes

1. **Pas d'embeddings**: Claude ne fournit pas d'embeddings
   - âœ… **Solution**: Embeddings locaux (gratuits!)
   - ModÃ¨le: `all-MiniLM-L6-v2`

2. **Format de rÃ©ponse**: LÃ©gÃ¨rement diffÃ©rent d'OpenAI
   - âœ… DÃ©jÃ  gÃ©rÃ© dans le code

3. **Limites de tokens**: 
   - Input: 200K tokens
   - Output: 4096 tokens (configurÃ© dans le code)

---

## ğŸ’¬ Exemples d'Utilisation

### CLI Interactive

```bash
$ python rag_query.py

ğŸ¤– Initializing Claude: claude-3-5-sonnet-20241022
âœ… System ready!

ğŸ’¬ Question: Quelles rÃ¨gles pour document retail franÃ§ais?

âœ… RÃ©ponse:
Pour un document retail franÃ§ais, voici les rÃ¨gles obligatoires:

1. RÃ¨gle 1.1 - Inclure les disclaimers retail
   - Disclaimer requis: FR_PRES_RET_SAS
   - Source: rules_database.json

2. RÃ¨gle 1.5 - Glossaire des termes techniques
   - Obligatoire en fin de prÃ©sentation
   
3. RÃ¨gle 1.11 - Ã‰viter les anglicismes
   - Ou les dÃ©finir dans le glossaire

ğŸ“š Sources: 5 documents
```

### Python API

```python
from rag_query import ComplianceRAG

# Initialiser avec Claude
rag = ComplianceRAG()

# Poser une question
result = rag.query("Quelles rÃ¨gles pour retail?")
print(result['answer'])

# Le reste est identique!
```

---

## ğŸ“Š Performance avec Claude

### Temps de RÃ©ponse

| OpÃ©ration | Temps |
|-----------|-------|
| Construction base (premiÃ¨re fois) | 3-5 min |
| Recherche seule | 50-200ms |
| RAG complet (avec Claude) | 2-4 sec |

### CoÃ»ts EstimÃ©s

Avec **Claude 3.5 Sonnet**:

| OpÃ©ration | CoÃ»t |
|-----------|------|
| Construction base (une fois) | ~$0.05 |
| RequÃªte simple | ~$0.002 |
| 1000 requÃªtes | ~$2.00 |

**Note**: Moins cher que GPT-4, qualitÃ© similaire!

---

## ğŸ” Embeddings Locaux

### Pourquoi Local?

Claude ne fournit pas d'embeddings, donc nous utilisons un modÃ¨le local:

```bash
EMBEDDING_MODEL=all-MiniLM-L6-v2
```

### Avantages

- âœ… **Gratuit** - Pas de coÃ»t API
- âœ… **Rapide** - ExÃ©cution locale
- âœ… **PrivÃ©** - DonnÃ©es restent locales
- âœ… **Multilingue** - Support EN, FR, DE

### QualitÃ©

- âœ… TrÃ¨s bonne pour la plupart des cas
- âœ… OptimisÃ© pour recherche sÃ©mantique
- âš ï¸ LÃ©gÃ¨rement infÃ©rieur Ã  OpenAI embeddings
- âœ… Suffisant pour notre cas d'usage

### Alternative (Meilleure QualitÃ©)

Pour amÃ©liorer la qualitÃ© des embeddings:

```bash
EMBEDDING_MODEL=all-mpnet-base-v2
```

Plus lent mais meilleure qualitÃ©.

---

## ğŸ› Troubleshooting

### Erreur: "ANTHROPIC_API_KEY not set"

**Solution**: VÃ©rifier que `.env` contient:
```bash
ANTHROPIC_API_KEY=sk-ant-api03-...
```

### Erreur: "No module named 'langchain_anthropic'"

**Solution**: RÃ©installer les dÃ©pendances:
```bash
pip install -r requirements.txt
```

### Erreur: "Rate limit exceeded"

**Solution**: 
1. Attendre quelques secondes
2. Ou utiliser Claude Haiku (moins de limites):
```bash
LLM_MODEL=claude-3-haiku-20240307
```

### RÃ©ponses trop courtes

**Solution**: Augmenter max_tokens dans `rag_query.py` ligne 84:
```python
max_tokens=8192  # Au lieu de 4096
```

### Embeddings trop lents

**Solution**: Utiliser un modÃ¨le plus petit:
```bash
EMBEDDING_MODEL=all-MiniLM-L6-v2  # DÃ©jÃ  configurÃ©
```

---

## âœ… Checklist de VÃ©rification

Avant de commencer:

- [x] ClÃ© Claude configurÃ©e dans `.env`
- [x] DÃ©pendances installÃ©es (`pip install -r requirements.txt`)
- [x] Embeddings locaux configurÃ©s
- [x] ModÃ¨le Claude sÃ©lectionnÃ© (Sonnet par dÃ©faut)
- [ ] Base vectorielle construite (`python build_vectorstore.py --rebuild`)
- [ ] SystÃ¨me testÃ© (`python rag_query.py`)

---

## ğŸ‰ PrÃªt!

Votre systÃ¨me RAG utilise maintenant **Claude 3.5 Sonnet**!

### DÃ©marrer

```bash
python quick_start.py
```

### Ou Manuel

```bash
python build_vectorstore.py --rebuild
python rag_query.py
```

---

## ğŸ“š Ressources

### Documentation Claude

- **Console**: https://console.anthropic.com/
- **API Docs**: https://docs.anthropic.com/
- **Pricing**: https://www.anthropic.com/pricing

### Documentation SystÃ¨me

- **README.md**: Guide complet du systÃ¨me
- **SETUP_GUIDE.md**: Installation dÃ©taillÃ©e
- **demo.ipynb**: Exemples interactifs

---

## ğŸ’¡ Conseils

### Pour Meilleure QualitÃ©

1. Utiliser **Claude 3.5 Sonnet** (dÃ©jÃ  configurÃ©)
2. Augmenter `TOP_K_RESULTS` Ã  7-10
3. Utiliser `all-mpnet-base-v2` pour embeddings

### Pour Meilleure Vitesse

1. Utiliser **Claude 3 Haiku**
2. RÃ©duire `TOP_K_RESULTS` Ã  3
3. Garder `all-MiniLM-L6-v2` pour embeddings

### Pour Ã‰conomiser

1. Utiliser **Claude 3 Haiku** ($0.25/M tokens)
2. Limiter `max_tokens` Ã  2048
3. Cacher les rÃ©sultats frÃ©quents

---

**Version**: 1.0 (Claude Edition)  
**Date**: 2025-11-05  
**LLM**: Claude 3.5 Sonnet  
**Embeddings**: Local (all-MiniLM-L6-v2)  
**Statut**: âœ… **PRÃŠT Ã€ L'EMPLOI**
