"""
Compliance Checklist Extractor
G√©n√®re une checklist de conformit√© √† partir des r√®gles
Chaque r√®gle ‚Üí Liste de champs √† extraire du PowerPoint
"""
from __future__ import annotations

import json
import time
from pathlib import Path
from typing import Dict, List, Any, Optional
from dataclasses import dataclass, asdict, field

from groq import Groq


@dataclass
class ComplianceCheckItem:
    """Un item de la checklist de conformit√©"""
    rule_id: str
    rule_category: str
    rule_description: str
    slide_location: str  # "slide_1", "slide_2", "any", "every_slide"
    
    # Champs √† extraire du PowerPoint
    fields_to_extract: List[Dict[str, Any]]
    
    # Crit√®res de validation
    validation_criteria: Dict[str, Any]
    
    # Priorit√©
    severity: str  # "critique", "majeure", "mineure"
    required: bool
    
    # NOUVEAU : R√©f√©rences externes
    external_references: List[Dict[str, Any]] = field(default_factory=list)
    
    # NOUVEAU : R√®gles conditionnelles
    conditional_rules: List[Dict[str, Any]] = field(default_factory=list)
    
    # NOUVEAU : Validations de format
    format_validations: List[Dict[str, Any]] = field(default_factory=list)
    
    # NOUVEAU : Validation multi-niveau
    validation_priority: int = 1  # 0=critique, 1=haute, 2=normale, 3=basse
    field_dependencies: List[str] = field(default_factory=list)  # Champs requis avant validation
    
    def to_dict(self) -> Dict[str, Any]:
        return asdict(self)


class ComplianceChecklistGenerator:
    """G√©n√©rateur de checklist de conformit√© avec Groq LLM"""
    
    SUPPORTED_LOCALES = ["fr_FR", "en_US", "de_DE"]
    
    def __init__(self, groq_api_key: str, rules_file: Path, enable_cache: bool = True, locale: str = "fr_FR"):
        self.client = Groq(api_key=groq_api_key)
        self.model = "llama-3.3-70b-versatile"
        self.rules_file = rules_file
        self.rules_data = self._load_rules()
        self.enable_cache = enable_cache
        self.cache = {} if enable_cache else None
        self.cache_file = rules_file.parent / "checklist_cache.json"
        self.locale = locale if locale in self.SUPPORTED_LOCALES else "fr_FR"
        if enable_cache:
            self._load_cache()
    
    def _load_rules(self) -> Dict[str, Any]:
        """Charge les r√®gles"""
        with self.rules_file.open("r", encoding="utf-8") as f:
            return json.load(f)
    
    def _load_cache(self):
        """Charge le cache depuis le fichier"""
        if self.cache_file.exists():
            try:
                with open(self.cache_file, 'r', encoding='utf-8') as f:
                    self.cache = json.load(f)
                print(f"üìÇ Cache charg√© : {len(self.cache)} entr√©es")
            except Exception as e:
                print(f"‚ö†Ô∏è  Erreur chargement cache : {e}")
                self.cache = {}
    
    def _save_cache(self):
        """Sauvegarde le cache"""
        if self.enable_cache and self.cache:
            try:
                with open(self.cache_file, 'w', encoding='utf-8') as f:
                    json.dump(self.cache, f, ensure_ascii=False, indent=2)
            except Exception as e:
                print(f"‚ö†Ô∏è  Erreur sauvegarde cache : {e}")
    
    def _get_cache_key(self, rule: Dict[str, Any]) -> str:
        """G√©n√®re une cl√© de cache pour une r√®gle"""
        rule_id = rule.get("rule_id", "")
        description = rule.get("description", "")
        # Hash simple bas√© sur id + premiers 100 caract√®res description
        import hashlib
        content = f"{rule_id}_{description[:100]}"
        return hashlib.md5(content.encode()).hexdigest()
    
    def _determine_slide_location(self, rule: Dict[str, Any]) -> str:
        """D√©termine la cat√©gorie de r√®gle avec analyse LLM intelligente"""
        slide_number = rule.get("slide_number", "any")
        category = rule.get("category", "global")
        description = rule.get("description", "").lower()
        
        # M√©thode 1 : D√©tection rapide par mots-cl√©s (fallback)
        if (slide_number == "1" or category == "page_de_garde" or
            any(kw in description for kw in ["page de garde", "cover", "premi√®re page", "titre"])):
            return "page_de_garde"
        
        elif (slide_number == "2" or category == "slide_2" or
              any(kw in description for kw in ["slide 2", "apr√®s la page de garde", "deuxi√®me slide"])):
            return "slide_2"
        
        elif any(kw in description for kw in ["fin de pr√©sentation", "derni√®re slide", "glossaire"]):
            return "page_finale"
        
        elif (slide_number and slide_number not in ["any", "global", "1", "2"] or
              category in ["performances", "ESG", "valeurs", "strat√©gies"]):
            return "pages_suivantes"
        
        # M√©thode 2 : Analyse LLM intelligente pour cas ambigus
        if not slide_number or slide_number in ["any", "global"]:
            return self._llm_detect_slide_location(rule)
        
        return "regles_generales"
    
    def _llm_detect_slide_location(self, rule: Dict[str, Any]) -> str:
        """D√©tection intelligente via LLM pour cas ambigus"""
        description = rule.get("description", "")
        category = rule.get("category", "")
        
        prompt = f"""Tu es expert en structure de pr√©sentations PowerPoint financi√®res.

R√àGLE: {description}
CAT√âGORIE: {category}

QUESTION: Cette r√®gle s'applique √† quel(s) slide(s) ?

CHOIX POSSIBLES:
- page_de_garde (slide 1 uniquement)
- slide_2 (slide 2 uniquement, disclaimers)
- pages_suivantes (slides 3+, contenu)
- page_finale (derni√®re slide uniquement)
- regles_generales (tous les slides)

R√©ponds UNIQUEMENT avec un mot parmi : page_de_garde, slide_2, pages_suivantes, page_finale, regles_generales"""
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.0,
                max_tokens=50
            )
            
            content = response.choices[0].message.content
            if content is None:
                return "regles_generales"
            
            location = content.strip().lower()
            valid_locations = ["page_de_garde", "slide_2", "pages_suivantes", "page_finale", "regles_generales"]
            
            if location in valid_locations:
                return location
        except Exception:
            pass
        
        return "regles_generales"
    
    def generate_check_item(self, rule: Dict[str, Any]) -> ComplianceCheckItem:
        """G√©n√®re un item de checklist pour une r√®gle avec extraction intelligente 2-passes"""
        rule_id = rule.get("rule_id", "N/A")
        category = rule.get("category", "N/A")
        description = rule.get("description", "")
        validation_type = rule.get("validation_type", "presence")
        severity = rule.get("severity", "mineure")
        required = rule.get("required", True)
        
        slide_location = self._determine_slide_location(rule)
        
        # V√©rifier cache
        if self.enable_cache and self.cache:
            cache_key = self._get_cache_key(rule)
            if cache_key in self.cache:
                print(f"üìÇ {rule_id}: Depuis cache")
                cached_data = self.cache[cache_key]
                return ComplianceCheckItem(
                    rule_id=rule_id,
                    rule_category=category,
                    rule_description=description,
                    slide_location=slide_location,
                    fields_to_extract=cached_data.get("fields_to_extract", []),
                    validation_criteria=cached_data.get("validation_criteria", {}),
                    severity=severity,
                    required=required,
                    external_references=cached_data.get("external_references", []),
                    conditional_rules=cached_data.get("conditional_rules", []),
                    format_validations=cached_data.get("format_validations", [])
                )
        
        # ============ EXTRACTION AVEC PROMPT D√âTAILL√â OPTIMIS√â ============
        prompt = f"""Tu es un expert en conformit√© de documents financiers.

R√àGLE DE CONFORMIT√â:
ID: {rule_id}
Cat√©gorie: {category}
Description: {description}
Type validation: {validation_type}
Localisation: {slide_location}

‚ö†Ô∏è INSTRUCTIONS CRITIQUES POUR L'EXTRACTION DES CHAMPS ‚ö†Ô∏è

**R√àGLE #1 - S√âPARATION STRICTE**: 
Si la r√®gle mentionne "X ET Y" ou "X/Y/Z" ‚Üí cr√©e des champs DISTINCTS pour chaque √©l√©ment.

EXEMPLES OBLIGATOIRES:
- "√©tudes/donn√©es/graphiques" avec "source et date" ‚Üí 6 CHAMPS:
  * source_etude, date_etude
  * source_donnee_chiffree, date_donnee_chiffree  
  * source_graphique, date_graphique

- "nom et code ISIN" ‚Üí 2 CHAMPS: nom_fonds, code_isin

- "performances YTD, 5 ans, 10 ans" ‚Üí 3 CHAMPS:
  * performance_ytd
  * performance_5ans
  * performance_10ans

**R√àGLE #2 - UN CONCEPT = UN CHAMP**:
‚ùå INTERDIT: "source_et_date", "nom_et_code", "titre_et_description"
‚úÖ CORRECT: Toujours s√©parer en champs individuels

**R√àGLE #3 - EXHAUSTIVIT√â**:
Liste TOUS les √©l√©ments (contenu + format + style + position)

**R√àGLE #4 - NOMS PROFESSIONNELS**:
Utilise snake_case pr√©cis (source_etude, date_publication_graphique, taille_police_titre)

**R√àGLE #5 - √âCHAPPEMENT JSON OBLIGATOIRE POUR LES REGEX**:
Dans le champ "regex_pattern", TOUTES les barres obliques inverses (\) DOIVENT √™tre doubl√©es (\\).
‚ùå INCORRECT: "\d{{4}}"
‚úÖ CORRECT: "\\d{{4}}"
C'est une exigence JSON critique.

T√ÇCHE: G√©n√®re UNE SEULE checklist enrichie pour cette r√®gle.
IMPORTANT: Groupe TOUS les champs de cette r√®gle dans une seule r√©ponse.

D√âTECTION FOOTER: Si la r√®gle mentionne "bas de page", "footer", "pied de slide", ajoute "footer_location": true dans le champ.

Pour CHAQUE √©l√©ment √† v√©rifier, sp√©cifie:

1. **field_name**: Nom technique du champ (snake_case, ex: "source_etude", "date_graphique")
2. **extraction_method**: 
   - "text_search": Chercher texte sp√©cifique
   - "text_presence": V√©rifier pr√©sence texte
   - "style_check": V√©rifier style (gras, couleur, taille)
   - "position_check": V√©rifier position/ordre
   - "data_extraction": Extraire donn√©e (date, nombre, liste)
   - "regex_match": Validation regex
   - "external_lookup": V√©rifier dans document externe
3. **search_keywords**: Mots-cl√©s pour trouver ce champ
4. **auto_synonyms**: Synonymes et variations linguistiques (FR, EN, DE) - OBLIGATOIRE
5. **validation_priority**: 0=critique, 1=haute, 2=normale, 3=basse
6. **depends_on**: Liste de champs requis avant validation (ex: ["disclaimer_text"] requis avant "disclaimer_bold")
7. **expected_format**: Format attendu (optionnel)
8. **validation_rule**: R√®gle de validation sp√©cifique
9. **regex_pattern**: Pattern regex si validation format (optionnel)
10. **external_doc_type**: Type de document externe si applicable (optionnel)
11. **external_doc_ref**: R√©f√©rence exacte dans le document externe (optionnel)

LANGUES SUPPORT√âES:
G√©n√®re TOUJOURS search_keywords et auto_synonyms en 3 langues:
- FR (Fran√ßais)
- EN (English)
- DE (Deutsch)

EXEMPLES CONCRETS D'EXTRACTION PR√âCISE:

R√®gle: "Les √©tudes/donn√©es chiffr√©es/graphiques doivent faire l'objet d'un renvoi pr√©cisant la source et la date"
‚Üí Champs (PR√âCIS, S√âPAR√âS) :
{{
  "field_name": "source_etude",
  "extraction_method": "text_search",
  "search_keywords": ["source", "√©tude", "study source", "Studienquelle"],
  "auto_synonyms": {{
    "fr": ["origine √©tude", "provenance √©tude", "r√©f√©rence √©tude"],
    "en": ["study origin", "study reference", "research source"],
    "de": ["Studienherkunft", "Studienreferenz", "Forschungsquelle"]
  }},
  "validation_rule": "must_be_present",
  "validation_priority": 0,
  "depends_on": [],
  "footer_location": true
}},
{{
  "field_name": "date_etude",
  "extraction_method": "regex_match",
  "search_keywords": ["date", "ann√©e", "study date", "Studiendatum"],
  "auto_synonyms": {{
    "fr": ["date publication", "ann√©e publication", "p√©riode √©tude"],
    "en": ["publication date", "study year", "research period"],
    "de": ["Ver√∂ffentlichungsdatum", "Studienjahr", "Forschungszeitraum"]
  }},
  "expected_format": "YYYY ou MM/YYYY",
  "validation_rule": "must_match_format",
  "validation_priority": 0,
  "depends_on": [],
  "regex_pattern": "20[0-9]{{2}}|(0[1-9]|1[0-2])/20[0-9]{{2}}",
  "footer_location": true
}},
{{
  "field_name": "source_donnee_chiffree",
  "extraction_method": "text_search",
  "search_keywords": ["source", "donn√©es", "data source", "Datenquelle"],
  "auto_synonyms": {{
    "fr": ["origine donn√©es", "provenance chiffres", "source statistiques"],
    "en": ["data origin", "statistics source", "figures source"],
    "de": ["Datenherkunft", "Statistikquelle", "Zahlenquelle"]
  }},
  "validation_rule": "must_be_present",
  "validation_priority": 0,
  "depends_on": [],
  "footer_location": true
}},
{{
  "field_name": "date_donnee_chiffree",
  "extraction_method": "regex_match",
  "search_keywords": ["date", "donn√©es", "data date", "Datendatum"],
  "auto_synonyms": {{
    "fr": ["date collecte", "p√©riode donn√©es", "actualisation"],
    "en": ["collection date", "data period", "update date"],
    "de": ["Erhebungsdatum", "Datenperiode", "Aktualisierungsdatum"]
  }},
  "expected_format": "YYYY ou MM/YYYY",
  "validation_rule": "must_match_format",
  "validation_priority": 0,
  "depends_on": [],
  "regex_pattern": "20[0-9]{{2}}|(0[1-9]|1[0-2])/20[0-9]{{2}}",
  "footer_location": true
}},
{{
  "field_name": "source_graphique",
  "extraction_method": "text_search",
  "search_keywords": ["source", "graphique", "chart source", "Diagrammquelle"],
  "auto_synonyms": {{
    "fr": ["origine graphique", "provenance visualisation", "source sch√©ma"],
    "en": ["chart origin", "visualization source", "diagram source"],
    "de": ["Diagrammherkunft", "Visualisierungsquelle", "Schemaherkunft"]
  }},
  "validation_rule": "must_be_present",
  "validation_priority": 0,
  "depends_on": [],
  "footer_location": true
}},
{{
  "field_name": "date_graphique",
  "extraction_method": "regex_match",
  "search_keywords": ["date", "graphique", "chart date", "Diagrammdatum"],
  "auto_synonyms": {{
    "fr": ["date cr√©ation graphique", "p√©riode repr√©sent√©e", "actualisation graphique"],
    "en": ["chart creation date", "period shown", "chart update"],
    "de": ["Diagrammerstellungsdatum", "dargestellter Zeitraum", "Diagrammaktualisierung"]
  }},
  "expected_format": "YYYY ou MM/YYYY",
  "validation_rule": "must_match_format",
  "validation_priority": 0,
  "depends_on": [],
  "regex_pattern": "20[0-9]{{2}}|(0[1-9]|1[0-2])/20[0-9]{{2}}",
  "footer_location": true
}}

R√®gle: "Page de garde doit indiquer nom du fonds, mois et ann√©e (format MM/YYYY), mention 'document promotionnel'"
‚Üí Champs:
{{
  "field_name": "nom_fonds",
  "extraction_method": "text_search",
  "search_keywords": ["nom", "fonds", "fund name", "Fondsname"],
  "auto_synonyms": {{
    "fr": ["d√©nomination", "intitul√©", "appellation"],
    "en": ["fund title", "fund denomination", "product name"],
    "de": ["Fonds", "Produktname", "Bezeichnung"]
  }},
  "expected_format": "text",
  "validation_rule": "must_be_present",
  "validation_priority": 0,
  "depends_on": []
}},
{{
  "field_name": "date_document",
  "extraction_method": "regex_match",
  "search_keywords": ["date", "mois", "ann√©e", "month", "year", "Monat", "Jahr"],
  "auto_synonyms": {{
    "fr": ["datation", "p√©riode", "mill√©sime"],
    "en": ["period", "vintage", "edition"],
    "de": ["Datum", "Zeitraum", "Jahrgang"]
  }},
  "expected_format": "MM/YYYY ou Mois YYYY",
  "validation_rule": "must_match_format",
  "validation_priority": 0,
  "depends_on": [],
  "regex_pattern": "(0[1-9]|1[0-2])/20[0-9]{{2}}|([Jj]anvier|[Ff]√©vrier|[Mm]ars|[Aa]vril|[Mm]ai|[Jj]uin|[Jj]uillet|[Aa]o√ªt|[Ss]eptembre|[Oo]ctobre|[Nn]ovembre|[Dd]√©cembre)\\s+20[0-9]{{2}}"
}},
{{
  "field_name": "mention_promotionnel",
  "extraction_method": "text_presence",
  "search_keywords": ["document promotionnel", "promotional document", "Werbedokument"],
  "auto_synonyms": {{
    "fr": ["document marketing", "support commercial", "mat√©riel publicitaire"],
    "en": ["marketing material", "advertising document", "promotional material"],
    "de": ["Marketingdokument", "Werbematerial", "Verkaufsunterlage"]
  }},
  "expected_format": "exact_text",
  "validation_rule": "must_contain_exact_text",
  "validation_priority": 0,
  "depends_on": []
}}

R√®gle: "Disclaimer PRIIPS en gras, m√™me taille que texte principal"
‚Üí Champs:
{{
  "field_name": "disclaimer_priips_text",
  "extraction_method": "text_search",
  "search_keywords": ["PRIIPS", "DIC", "DICI", "KID"],
  "auto_synonyms": {{
    "fr": ["document d'informations cl√©s", "informations essentielles"],
    "en": ["key information document", "essential information"],
    "de": ["Basisinformationsblatt", "wesentliche Informationen"]
  }},
  "validation_rule": "must_be_present",
  "validation_priority": 0,
  "depends_on": []
}},
{{
  "field_name": "disclaimer_priips_bold",
  "extraction_method": "style_check",
  "search_keywords": ["gras", "bold", "fett"],
  "auto_synonyms": {{
    "fr": ["caract√®res gras", "texte en gras"],
    "en": ["bold text", "bold font"],
    "de": ["fetter Text", "Fettdruck"]
  }},
  "expected_format": "bold=true",
  "validation_rule": "style_must_be_bold",
  "validation_priority": 1,
  "depends_on": ["disclaimer_priips_text"]
}},
{{
  "field_name": "disclaimer_priips_font_size",
  "extraction_method": "style_check",
  "search_keywords": ["taille", "font size", "Schriftgr√∂√üe"],
  "auto_synonyms": {{
    "fr": ["taille de police", "corps de texte"],
    "en": ["font size", "text size"],
    "de": ["Schriftgr√∂√üe", "Textgr√∂√üe"]
  }},
  "expected_format": "same_as_body_text",
  "validation_rule": "size_equals_body",
  "validation_priority": 1,
  "depends_on": ["disclaimer_priips_text"]
}}

R√®gle: "Disclaimer PRIIPS obligatoire (cf. Glossaire des disclaimers, r√©f√©rence DISCLAIMER_PRIIPS_V2)"
‚Üí Champs:
{{
  "field_name": "disclaimer_priips",
  "extraction_method": "external_lookup",
  "search_keywords": ["PRIIPS", "DIC", "DICI", "document d'informations cl√©s"],
  "expected_format": "exact_match_from_glossary",
  "validation_rule": "must_match_external_reference",
  "external_doc_type": "glossaire_disclaimers",
  "external_doc_ref": "DISCLAIMER_PRIIPS_V2"
}}

R√®gle: "Performances obligatoires SAUF si pr√©sentation de gamme"
‚Üí Champs:
{{
  "field_name": "performance_data",
  "extraction_method": "data_extraction",
  "search_keywords": ["performance", "rendement", "return"],
  "validation_rule": "conditional_presence",
  "condition": "required_unless_presentation_type_is_gamme"
}}

R√®gle: "V√©rifier que le fonds est autoris√© dans les pays mentionn√©s (cf. Registration of Funds Excel)"
‚Üí Champs:
{{
  "field_name": "pays_mentions",
  "extraction_method": "data_extraction",
  "search_keywords": ["pays", "country", "zone g√©ographique"],
  "validation_rule": "must_be_in_authorized_list",
  "external_doc_type": "registration_of_funds",
  "external_doc_ref": "authorized_countries_list"
}}

R√®gle: "Montants en euros avec format: 1 234,56 ‚Ç¨ ou 1.234,56 EUR"
‚Üí Champs:
{{
  "field_name": "montant_euro",
  "extraction_method": "regex_match",
  "search_keywords": ["euro", "‚Ç¨", "EUR", "montant"],
  "expected_format": "1 234,56 ‚Ç¨ ou 1.234,56 EUR",
  "validation_rule": "must_match_currency_format",
  "regex_pattern": "[0-9]{{1,3}}([\\s.]?[0-9]{{3}})*,[0-9]{{2}}\\s*(‚Ç¨|EUR)"
}}

ANALYSE DES R√âF√âRENCES EXTERNES:
Si la r√®gle mentionne:
- "Glossaire", "disclaimers" ‚Üí external_doc_type: "glossaire_disclaimers"
- "Prospectus", "DICI", "KID" ‚Üí external_doc_type: "prospectus"
- "Registration", "pays autoris√©s" ‚Üí external_doc_type: "registration_of_funds"

ANALYSE DES CONDITIONS:
Si la r√®gle contient:
- "SAUF SI", "UNIQUEMENT SI", "√Ä L'EXCEPTION DE" ‚Üí Cr√©er r√®gle conditionnelle
- "SELON LE TYPE", "D√âPEND DE" ‚Üí Cr√©er r√®gle conditionnelle

ANALYSE DES FORMATS:
Si la r√®gle sp√©cifie un format pr√©cis:
- Date (JJ/MM/AAAA, MM/YYYY, etc.) ‚Üí regex_pattern
- Montant (devise, s√©parateurs) ‚Üí regex_pattern
- Email, t√©l√©phone, URL ‚Üí regex_pattern
- Pourcentage, nombre ‚Üí regex_pattern

R√âPONDS UNIQUEMENT EN JSON:
{{
  "fields_to_extract": [
    {{
      "field_name": "nom_du_champ",
      "extraction_method": "text_search|text_presence|style_check|position_check|data_extraction|regex_match|external_lookup",
      "search_keywords": ["mot1_fr", "mot1_en", "mot1_de"],
      "auto_synonyms": {{
        "fr": ["synonyme1", "synonyme2"],
        "en": ["synonym1", "synonym2"],
        "de": ["Synonym1", "Synonym2"]
      }},
      "validation_priority": 0,
      "depends_on": ["champ_requis_avant"],
      "expected_format": "format attendu",
      "validation_rule": "r√®gle de validation",
      "regex_pattern": "pattern regex si applicable",
      "external_doc_type": "type doc externe si applicable",
      "external_doc_ref": "r√©f√©rence exacte si applicable",
      "footer_location": true  // SEULEMENT si bas de page/footer
    }}
  ],
  "validation_criteria": {{
    "check_type": "presence|format|style|order|value|external|conditional",
    "success_condition": "condition de succ√®s",
    "failure_action": "action si √©chec"
  }},
  "external_references": [
    {{
      "doc_type": "glossaire_disclaimers|prospectus|registration_of_funds",
      "reference": "r√©f√©rence exacte",
      "field_name": "champ concern√©",
      "match_type": "exact|fuzzy|contains",
      "similarity_threshold": 0.9
    }}
  ],
  "conditional_rules": [
    {{
      "condition_type": "unless|only_if|depends_on",
      "condition_field": "champ de condition",
      "condition_value": "valeur attendue",
      "applies_to_field": "champ cible",
      "explanation": "explication de la condition"
    }}
  ],
  "format_validations": [
    {{
      "field_name": "champ concern√©",
      "format_type": "date|currency|percentage|email|phone|url|number",
      "regex_pattern": "pattern regex",
      "expected_examples": ["exemple1", "exemple2"],
      "error_message": "message si non conforme"
    }}
  ],
  "validation_priority": 0,
  "field_dependencies": ["champ1", "champ2"]
}}"""

        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.1,
                max_tokens=2000
            )
            
            content = response.choices[0].message.content
            if content is None:
                raise ValueError("R√©ponse LLM vide")
            content = content.strip()
            
            # Nettoyage
            if content.startswith("```"):
                content = "\n".join(content.split("\n")[1:-1])
            
            # Correction automatique des barres obliques pour les regex JSON
            import re
            content = re.sub(r'("regex_pattern":\s*")(.*?)(")', 
                             lambda m: m.group(1) + m.group(2).replace('\\', '\\\\') + m.group(3), 
                             content)

            result = json.loads(content)
            
            # Extraire les nouvelles sections enrichies
            external_refs = result.get("external_references", [])
            conditional_rules_data = result.get("conditional_rules", [])
            format_validations_data = result.get("format_validations", [])
            validation_priority = result.get("validation_priority", 1)
            field_dependencies = result.get("field_dependencies", [])
            
            check_item = ComplianceCheckItem(
                rule_id=rule_id,
                rule_category=category,
                rule_description=description,
                slide_location=slide_location,
                fields_to_extract=result.get("fields_to_extract", []),
                validation_criteria=result.get("validation_criteria", {}),
                severity=severity,
                required=required,
                external_references=external_refs,
                conditional_rules=conditional_rules_data,
                format_validations=format_validations_data,
                validation_priority=validation_priority,
                field_dependencies=field_dependencies
            )
            
            # Affichage enrichi
            extras = []
            if external_refs:
                extras.append(f"{len(external_refs)} ext.refs")
            if conditional_rules_data:
                extras.append(f"{len(conditional_rules_data)} conditions")
            if format_validations_data:
                extras.append(f"{len(format_validations_data)} formats")
            
            extras_str = f" ({', '.join(extras)})" if extras else ""
            print(f"‚úÖ {rule_id}: {len(check_item.fields_to_extract)} champs ‚Üí {slide_location}{extras_str}")
            
            # Sauvegarder en cache
            if self.enable_cache and self.cache is not None:
                cache_key = self._get_cache_key(rule)
                self.cache[cache_key] = {
                    "fields_to_extract": check_item.fields_to_extract,
                    "validation_criteria": check_item.validation_criteria,
                    "external_references": check_item.external_references,
                    "conditional_rules": check_item.conditional_rules,
                    "format_validations": check_item.format_validations
                }
            
            return check_item
            
        except Exception as e:
            print(f"‚ùå Erreur {rule_id}: {e}")
            
            # Fallback basique
            return ComplianceCheckItem(
                rule_id=rule_id,
                rule_category=category,
                rule_description=description,
                slide_location=slide_location,
                fields_to_extract=[],
                validation_criteria={"error": str(e)},
                severity=severity,
                required=required
            )
    
    def _extract_concepts_from_rule(self, description: str) -> List[str]:
        """PASS 1 : Extrait les concepts-cl√©s de la r√®gle (analyse s√©mantique)"""
        prompt = f"""Analyse cette r√®gle de conformit√© et extrais TOUS les concepts/√©l√©ments distincts mentionn√©s.

R√àGLE : {description}

INSTRUCTIONS :
1. Identifie CHAQUE √©l√©ment s√©par√© (ne groupe JAMAIS)
2. Si "source et date" ‚Üí liste ["source", "date"]
3. Si "√©tudes/donn√©es/graphiques" ‚Üí liste ["√©tudes", "donn√©es", "graphiques"]
4. Inclus aussi les attributs (taille, couleur, position, format, etc.)

R√©ponds UNIQUEMENT avec un tableau JSON de concepts.
Exemple : ["source", "date", "taille police", "position"]
"""
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.0,
                max_tokens=500
            )
            
            content = response.choices[0].message.content
            if content is None:
                return []
            
            content = content.strip()
            if content.startswith("```"):
                import re
                m = re.search(r"```(?:json)?\s*([\s\S]*?)\s*```", content)
                if m:
                    content = m.group(1)
            
            concepts = json.loads(content)
            return concepts if isinstance(concepts, list) else []
        except Exception as e:
            print(f"  ‚ö†Ô∏è  Erreur extraction concepts : {e}")
            return []
    
    def _generate_fields_from_concepts(self, rule_id: str, description: str, concepts: List[str], slide_location: str) -> Optional[Dict[str, Any]]:
        """PASS 2 : G√©n√®re les champs √† partir des concepts identifi√©s"""
        if not concepts:
            return None
        
        concepts_str = ", ".join(concepts)
        
        prompt = f"""Tu es expert en conformit√©. G√©n√®re des champs d'extraction PR√âCIS.

R√àGLE : {description}

CONCEPTS IDENTIFI√âS : {concepts_str}

Pour CHAQUE concept, cr√©e UN champ distinct avec :
- field_name (snake_case, pr√©cis, ex: "source_etude", "date_graphique")
- extraction_method
- search_keywords (FR, EN, DE)
- auto_synonyms (FR, EN, DE)
- validation_priority (0-3)
- depends_on (si d√©pendance)
- expected_format
- validation_rule
- regex_pattern (si format)

R√âPONDS UNIQUEMENT EN JSON :
{{
  "fields_to_extract": [...],
  "validation_criteria": {{}},
  "external_references": [],
  "conditional_rules": [],
  "format_validations": [],
  "validation_priority": 0,
  "field_dependencies": []
}}
"""
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.1,
                max_tokens=2000
            )
            
            content = response.choices[0].message.content
            if content is None:
                return None
            
            content = content.strip()
            if content.startswith("```"):
                import re
                m = re.search(r"```(?:json)?\s*([\s\S]*?)\s*```", content)
                if m:
                    content = m.group(1)
            
            result = json.loads(content)
            return result
        except Exception as e:
            print(f"  ‚ö†Ô∏è  Erreur g√©n√©ration champs : {e}")
            return None
    
    def _analyze_rule_semantics(self, description: str, category: str) -> Optional[Dict[str, Any]]:
        """PHASE 1: Analyse s√©mantique intelligente de la r√®gle"""
        prompt = f"""Analyse cette r√®gle de conformit√© et liste TOUS les √©l√©ments distincts √† v√©rifier.

R√àGLE: {description}

INSTRUCTIONS:
1. Si "X et Y" ou "X/Y" ‚Üí s√©pare en 2 concepts distincts
2. Si "√©tudes/donn√©es/graphiques" avec "source et date" ‚Üí 6 champs (source_etude, date_etude, source_donnee, date_donnee, source_graphique, date_graphique)
3. Liste TOUS attributs: contenu + style + format + position

R√âPONDS UNIQUEMENT avec un tableau JSON de concepts:
["concept1", "concept2", "concept3"]

Exemple:
R√®gle: "√©tudes/donn√©es doivent avoir source et date"
R√©ponse: ["source_etude", "date_etude", "source_donnee", "date_donnee"]
"""
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.0,
                max_tokens=500
            )
            
            content = response.choices[0].message.content
            if not content or content.strip() == "":
                return None
            
            content = content.strip()
            if content.startswith("```"):
                import re
                m = re.search(r"```(?:json)?\s*([\s\S]*?)\s*```", content)
                if m:
                    content = m.group(1).strip()
            
            # Parse as simple array
            concepts_list = json.loads(content)
            if not isinstance(concepts_list, list) or len(concepts_list) == 0:
                return None
            
            # Convert to expected format
            return {
                "field_concepts": [
                    {
                        "concept": c,
                        "type": "content",
                        "attributes": [],
                        "multiplicity": "single",
                        "description": ""
                    }
                    for c in concepts_list
                ],
                "rule_type": "presence",
                "complexity": "medium"
            }
        except Exception as e:
            print(f"  ‚ö†Ô∏è  Erreur analyse s√©mantique : {e}")
            return None
    
    def _generate_precise_fields(self, rule_id: str, description: str, category: str, 
                                slide_location: str, semantic_analysis: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """PHASE 2: G√©n√©ration pr√©cise des champs depuis l'analyse s√©mantique"""
        
        concepts = [c['concept'] for c in semantic_analysis.get("field_concepts", [])]
        concepts_str = ", ".join(concepts)
        
        prompt = f"""G√©n√®re des champs d'extraction pour cette r√®gle de conformit√©.

R√àGLE: {description}
CONCEPTS IDENTIFI√âS: {concepts_str}

Cr√©e UN CHAMP par concept avec:
- field_name (snake_case, ex: source_etude, date_graphique)
- extraction_method (text_search, data_extraction, style_check, regex_match)
- search_keywords (FR, EN, DE)
- auto_synonyms (fr/en/de avec 2-3 synonymes chacun)
- validation_priority (0-3)
- expected_format si applicable
- validation_rule
- regex_pattern si n√©cessaire

R√âPONDS EN JSON:
{{
  "fields_to_extract": [
    {{
      "field_name": "nom_champ",
      "extraction_method": "text_search",
      "search_keywords": ["mot", "word", "Wort"],
      "auto_synonyms": {{"fr": ["syn1"], "en": ["syn1"], "de": ["syn1"]}},
      "validation_priority": 0,
      "depends_on": [],
      "validation_rule": "must_be_present"
    }}
  ],
  "validation_criteria": {{}},
  "external_references": [],
  "conditional_rules": [],
  "format_validations": [],
  "validation_priority": 0,
  "field_dependencies": []
}}
"""
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.1,
                max_tokens=2500
            )
            
            content = response.choices[0].message.content
            if not content or content.strip() == "":
                return None
            
            content = content.strip()
            if content.startswith("```"):
                import re
                m = re.search(r"```(?:json)?\s*([\s\S]*?)\s*```", content)
                if m:
                    content = m.group(1).strip()
            
            result = json.loads(content)
            return result
        except Exception as e:
            print(f"  ‚ö†Ô∏è  Erreur g√©n√©ration pr√©cise : {e}")
            return None
    
    def generate_full_checklist(self) -> Dict[str, Any]:
        """G√©n√®re la checklist compl√®te"""
        rules = self.rules_data.get("rules", [])
        
        print(f"üìã G√©n√©ration checklist depuis {len(rules)} r√®gles...")
        print("=" * 70)
        
        # STRUCTURE CORRIG√âE - 5 CAT√âGORIES DE R√àGLES
        checklist_by_location = {
            "regles_generales": [],      # R√®gles g√©n√©rales (s'appliquent partout)
            "page_de_garde": [],         # R√®gles sp√©cifiques slide 1
            "slide_2": [],               # R√®gles sp√©cifiques slide 2
            "pages_suivantes": [],       # R√®gles sp√©cifiques slides 3+
            "page_finale": []             # R√®gles derni√®re slide uniquement
        }
        
        all_check_items = []
        
        for i, rule in enumerate(rules, 1):
            rule_id = rule.get("rule_id", "N/A")
            category = rule.get("category", "unknown")
            
            print(f"[{i}/{len(rules)}] {rule_id} ({category})...")
            
            # G√©n√©rer check item
            check_item = self.generate_check_item(rule)
            all_check_items.append(check_item)
            
            # Organiser par cat√©gorie de r√®gle
            location = check_item.slide_location
            if location in checklist_by_location:
                checklist_by_location[location].append(check_item.to_dict())
            else:
                # Fallback vers r√®gles g√©n√©rales
                checklist_by_location["regles_generales"].append(check_item.to_dict())
            
            time.sleep(0.5)  # Rate limiting
        
        # Sauvegarder cache
        if self.enable_cache:
            self._save_cache()
            print(f"\nüìÇ Cache sauvegard√© : {len(self.cache or {})} entr√©es")
        
        # Statistiques
        total_fields = sum(
            len(item.fields_to_extract) 
            for item in all_check_items
        )
        
        total_external_refs = sum(
            len(item.external_references)
            for item in all_check_items
        )
        
        total_conditional_rules = sum(
            len(item.conditional_rules)
            for item in all_check_items
        )
        
        total_format_validations = sum(
            len(item.format_validations)
            for item in all_check_items
        )
        
        critical_rules = [
            item for item in all_check_items 
            if item.severity == "critique"
        ]
        
        # Grouper r√©f√©rences externes par type
        external_refs_by_type = {}
        for item in all_check_items:
            for ref in item.external_references:
                doc_type = ref.get("doc_type", "unknown")
                external_refs_by_type[doc_type] = external_refs_by_type.get(doc_type, 0) + 1
        
        checklist = {
            "compliance_checklist": checklist_by_location,
            "statistics": {
                "total_rules": len(rules),
                "total_check_items": len(all_check_items),
                "total_fields_to_extract": total_fields,
                "total_external_references": total_external_refs,
                "total_conditional_rules": total_conditional_rules,
                "total_format_validations": total_format_validations,
                "critical_rules": len(critical_rules),
                "rules_by_location": {
                    loc: len(items) 
                    for loc, items in checklist_by_location.items() 
                    if items
                },
                "rules_by_severity": {
                    "critique": len([i for i in all_check_items if i.severity == "critique"]),
                    "majeure": len([i for i in all_check_items if i.severity == "majeure"]),
                    "mineure": len([i for i in all_check_items if i.severity == "mineure"])
                },
                "external_references_by_type": external_refs_by_type
            },
            "metadata": {
                "model_used": self.model,
                "generation_method": "compliance_checklist_llm_enriched",
                "purpose": "PowerPoint extraction and validation with external docs and conditional rules",
                "features": [
                    "format_validation",
                    "external_references",
                    "conditional_rules",
                    "regex_patterns"
                ]
            }
        }
        
        return checklist
    
    def save_checklist(self, output_path: Path):
        """Sauvegarde la checklist"""
        checklist = self.generate_full_checklist()
        
        with output_path.open("w", encoding="utf-8") as f:
            json.dump(checklist, f, ensure_ascii=False, indent=2)
        
        print(f"\nüíæ Checklist sauvegard√©e: {output_path}")
        print(f"\nüìä STATISTIQUES:")
        stats = checklist["statistics"]
        print(f"  - R√®gles analys√©es: {stats['total_rules']}")
        print(f"  - Items de v√©rification: {stats['total_check_items']}")
        print(f"  - Champs √† extraire: {stats['total_fields_to_extract']}")
        print(f"  - R√®gles critiques: {stats['critical_rules']}")
        
        print(f"\n‚ú® FONCTIONNALIT√âS ENRICHIES:")
        print(f"  - R√©f√©rences externes: {stats['total_external_references']}")
        if stats['external_references_by_type']:
            for doc_type, count in stats['external_references_by_type'].items():
                print(f"    ‚Ä¢ {doc_type}: {count}")
        print(f"  - R√®gles conditionnelles: {stats['total_conditional_rules']}")
        print(f"  - Validations de format: {stats['total_format_validations']}")
        
        print(f"\nüìç PAR LOCATION:")
        for loc, count in stats['rules_by_location'].items():
            print(f"  - {loc}: {count} r√®gles")


def main():
    """G√©n√®re la checklist de conformit√©"""
    import sys
    from pathlib import Path
    
    scripts_dir = Path(__file__).parent.parent
    sys.path.insert(0, str(scripts_dir))
    
    from config import RULES_JSON, GROQ_API_KEY, EXTRACTED_DIR
    
    if not RULES_JSON.exists():
        print(f"‚ùå Fichier introuvable: {RULES_JSON}")
        return
    
    print("GENERATEUR DE CHECKLIST DE CONFORMITE")
    print("=" * 70)
    
    try:
        generator = ComplianceChecklistGenerator(
            groq_api_key=GROQ_API_KEY or "",
            rules_file=RULES_JSON
        )
        
        output_path = EXTRACTED_DIR / "compliance_checklist.json"
        generator.save_checklist(output_path)
        
        print("\n‚úÖ Checklist g√©n√©r√©e avec succ√®s!")
        print(f"\nüìå PROCHAINE √âTAPE:")
        print(f"   Utiliser cette checklist pour extraire les donn√©es du PowerPoint")
        
    except Exception as e:
        print(f"‚ùå Erreur: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()